// Copyright 2019, OpenTelemetry Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package opentelemetry.proto.metrics.v1;

import "opentelemetry/proto/common/v1/common.proto";
import "opentelemetry/proto/resource/v1/resource.proto";

option java_multiple_files = true;
option java_package = "io.opentelemetry.proto.metrics.v1";
option java_outer_classname = "MetricsProto";
option go_package = "github.com/open-telemetry/opentelemetry-proto/gen/go/metrics/v1";

// A collection of InstrumentationLibraryMetrics from a Resource.
message ResourceMetrics {
  // The resource for the metrics in this message.
  // If this field is not set then no resource info is known.
  opentelemetry.proto.resource.v1.Resource resource = 1;

  // A list of metrics that originate from a resource.
  repeated InstrumentationLibraryMetrics instrumentation_library_metrics = 2;
}

// A collection of Metrics produced by an InstrumentationLibrary.
message InstrumentationLibraryMetrics {
  // The instrumentation library information for the metrics in this message.
  // If this field is not set then no library info is known.
  opentelemetry.proto.common.v1.InstrumentationLibrary instrumentation_library = 1;

  // A list of metrics that originate from an instrumentation library.
  repeated Metric metrics = 2;
}

// Metric contains one or more timeseries.
//
// The data model and relation between entities is shown in the
// diagram below.  Here, "DataPoint" is the term used to refer to any
// one of the specific data point kinds, and "points" is the term use
// to refer to any one of the lists of points contained in the Metric.
//
// - Metric is composed of a MetricDescriptor and a list of data points.
// - MetricDescriptor contains a name, description, unit, kind, and value type.
// - Points is a list of DataPoints (shown vertically).
// - DataPoint contains timestamps, labels, and one of the value type fields.
//
//     Metric
//  +----------+         +------------------------+
//  |descriptor|-------->| MetricDescriptor       |
//  |          |         | name                   |
//  |          |         | description            |
//  |          |         | unit                   |
//  |    points|--+      | kind                   |
//  +----------+  |      | value type             |
//                |      +------------------------+
//                |
//                |      +---------------------------+
//                |      |DataPoint 1                |
//                v      |+------+------+   +------+ |
//             +-----+   ||label |label |...|label | |
//             |  1  |-->||value1|value2|...|valueN| |
//             +-----+   |+------+------+   +------+ |
//             |  .  |   |+-----+                    |
//             |  .  |   ||value|                    |
//             |  .  |   |+-----+                    |
//             |  .  |   +---------------------------+
//             |  .  |                   .
//             |  .  |                   .
//             |  .  |                   .
//             |  .  |   +---------------------------+
//             |  .  |   |DataPoint M                |
//             +-----+   |+------+------+   +------+ |
//             |  M  |-->||label |label |...|label | |
//             +-----+   ||value1|value2|...|valueN| |
//                       |+------+------+   +------+ |
//                       |+-----+                    |
//                       ||value|                    |
//                       |+-----+                    |
//                       +---------------------------+
//
// All DataPoint types have includes three common fields:
// - Labels are the optional key-value pairs associated with the data point.
// - StartTimeUnixNano MUST be set to the start of the interval when the
//   descriptor kind includes CUMULATIVE or DELTA.  This field is not set
//   for INSTANTANEOUS timeseries, where instead the TimeUnixNano field is
//   set for individual points.
// - TimeUnixNano MUST be set to:
//   - the end of the interval (CUMULATIVE or DELTA)
//   - the instantaneous time of the event (INSTANTANEOUS).
//
// The ValueType of the descriptor determines which of the repeated points
// fields is used.
message Metric {
  // Descriptor describes the Metric.
  //
  // N.B. "Descriptor" is a reserved term in protobuf, protoc
  // generates a field named "Descriptor_" thus we use "metric_descriptor".
  MetricDescriptor metric_descriptor = 1;

  // Data is a list of one or more DataPoints for a single metric. Only one of the
  // following fields is used for the data, depending on the type of the metric defined
  // by MetricDescriptor.value_type field.

  repeated ScalarDataPoint scalar_data_points = 2;
  repeated HistogramDataPoint histogram_data_points = 4;
  repeated SummaryDataPoint summary_data_points = 5;
}

// Defines a metric type and its schema.
message MetricDescriptor {
  // Name of the metric, including its DNS name prefix. It must be unique.
  string name = 1;

  // Description of the metric, which can be used in documentation.
  string description = 2;

  // Unit in which the metric value is reported. Follows the format
  // described by http://unitsofmeasure.org/ucum.html.
  string unit = 3;

  // ValueType is the type of values a metric has.  ValueType determines
  // which field of the DataPoint will be used for Metrics with this
  // descriptor.
  enum ValueType {
    // INVALID_TYPE is the default ValueType, it MUST not be used.
    INVALID_VALUE_TYPE = 0;

    // ScalarInt64 implies that the value is found in Metric.scalar_data_points[].value_int64.
    SCALAR_INT64 = 1;

    // ScalarDouble implies that the value is found in Metric.scalar_data_points[].value_double.
    SCALAR_DOUBLE = 2;

    // Histogram implies that the value is found in Metric.histogram_data_points[].histogram.
    HISTOGRAM = 3;

    // Summary implies that the value is found in Metric.summary_data_points[].summary.
    SUMMARY = 4;
  }

  // ValueType is the type of values this metric has.
  ValueType value_type = 4;

  // KindElement contains a set of bit masks used to construct Kind
  // enum values.  There are 7 bits used presently, broken into
  // groups:
  //
  //   _Temporality_ is the temporal quality of a metric, indicating
  //   how values relate to the time interval over which they are
  //   reported.  One of the 3 Temporality values MUST be set:
  //   CUMULATIVE, DELTA, or INSTANTANEOUS.
  //
  //   _Structure_ is the structural quality of a metric, indicating
  //   whether metric data describes a sum of measurements (ADDING) or
  //   a collection of individual measurements (GROUPING).  Value
  //   types may be interpreted differently depending on Structure.
  //   For example, a Histogram DataPoint may be computed for a
  //   Counter (ADDING) instrument or a ValueRecorder (GROUPING)
  //   instrument, and the Sum and Count of the resulting aggregation
  //   may be interpreted differently depending on structure.
  //
  //   _Monotonic_ is a boolean option that may be applied to
  //   ADDING-structure metrics.
  //
  //   _Asynchronous_ is a boolean option that may be applied to all
  //   metrics.  When set, an ASYNCHRONOUS kind indicates that the
  //   corresponding measurement was made through a callback called by
  //   the SDK.  When measurements originate from an OpenTelemetry
  //   API, the ASYNCHRONOUS kind allows the interpreter to recognize
  //   values that were emitted by the same callback invokation, which
  //   are permitted to record at most one value per label set under
  //   the specification.  This property can be safetly disregarded
  //   and not set when importing data from other sources, but when
  //   set its presence is always meaningful.  It means:
  //   - The count of events is a measure of the rate of SDK collection
  //     times the aggregated cardinality, therefore cannot be used
  //     to extrapolate application-specific rate information.
  //   - Measurements with the same Resource and StartTimeUnixNano
  //     form a meaningful ratio, and the set of measurements is coherent.
  //   - Trace context MUST not be set.
  //
  enum KindElement {
    // INVALID_KIND_MASK is not used.
    INVALID_KIND_MASK = 0;

    // One of the following three MUST be set. There are 3 exclusive
    // Temporality kinds.

    // INSTANTANEOUS is a metric whose values are measured at a particular
    // instant. The values are not aggregated over any time interval and are
    // unique per timestamp. As such, these metrics are not expected to have
    // an associated start time.
    INSTANTANEOUS = 0x1;

    // DELTA is a metric whose values are the aggregation of measurements
    // made over a time interval. Successive metrics contain aggregation of
    // values from continuous and non-overlapping intervals.
    //
    // The values for a DELTA metric are based only on the time interval
    // associated with one measurement cycle. There is no dependency on
    // previous measurements like is the case for CUMULATIVE metrics.
    //
    // For example, consider a system measuring the number of requests that
    // it receives and reports the sum of these requests every second as a
    // DELTA metric:
    //
    //   1. The system starts receiving at time=t_0.
    //   2. A request is received, the system measures 1 request.
    //   3. A request is received, the system measures 1 request.
    //   4. A request is received, the system measures 1 request.
    //   5. The 1 second collection cycle ends. A metric is exported for the
    //      number of requests received over the interval of time t_0 to
    //      t_0+1 with a value of 3.
    //   6. A request is received, the system measures 1 request.
    //   7. A request is received, the system measures 1 request.
    //   8. The 1 second collection cycle ends. A metric is exported for the
    //      number of requests received over the interval of time t_0+1 to
    //      t_0+2 with a value of 2.
    DELTA = 0x2;

    // CUMULATIVE is a metric whose values are the aggregation of
    // successively made measurements from a fixed start time until the last
    // reported measurement. This means that current values of a CUMULATIVE
    // metric depend on all previous measurements since the start time.
    // Because of this, the sender is required to retain this state in some
    // form. If this state is lost or invalidated, the CUMULATIVE metric
    // values MUST be reset and a new fixed start time following the last
    // reported measurement time sent MUST be used.
    //
    // For example, consider a system measuring the number of requests that
    // it receives and reports the sum of these requests every second as a
    // CUMULATIVE metric:
    //
    //   1. The system starts receiving at time=t_0.
    //   2. A request is received, the system measures 1 request.
    //   3. A request is received, the system measures 1 request.
    //   4. A request is received, the system measures 1 request.
    //   5. The 1 second collection cycle ends. A metric is exported for the
    //      number of requests received over the interval of time t_0 to
    //      t_0+1 with a value of 3.
    //   6. A request is received, the system measures 1 request.
    //   7. A request is received, the system measures 1 request.
    //   8. The 1 second collection cycle ends. A metric is exported for the
    //      number of requests received over the interval of time t_0 to
    //      t_0+2 with a value of 5.
    //   9. The system experiences a fault and loses state.
    //   10. The system recovers and resumes receiving at time=t_1.
    //   11. A request is received, the system measures 1 request.
    //   12. The 1 second collection cycle ends. A metric is exported for the
    //      number of requests received over the interval of time t_1 to
    //      t_0+1 with a value of 1.
    CUMULATIVE = 0x4;

    // One of the following two MUST be set. There are 2 exclusive
    // Structure kinds.

    // ADDING structure means the measurement determines a sum.  For
    // DELTA kind this is expressed as the change in sum since the
    // last collection.  For CUMULATIVE kind this is expressed as the
    // last collected value of the sum.  For INSTANTANEOUS kind this
    // is expressed as a scalar value that would be added into a Sum.
    ADDING = 0x8;

    // GROUPING structure means the value has been computed by
    // combining individual values in a meaningful aggregation.
    // GROUPING structure implies the sum of measurements is not
    // necessarily meaningful.  These may be expressed as DELTA
    // kind, indicating an aggregation of values since the last
    // collection, or as CUMULATIVE kind, indicating an aggregation
    // of values since the last StartTimeUnixNano reset.  These may
    // also be expressed as INSTANTANEOUS kind when reporting a
    // scalar value type.
    GROUPING = 0x10;

    // MONOTONIC may be set in conjunction with ADDING kinds.  When
    // set, MONOTONIC indicates that the calculated sum can be
    // monitored as a non-negative rate of change.
    //
    // For DELTA
    // kind, this implies non-negative value series.  For CUMULATIVE
    // kind, this implies a non-decreasing value series.
    //
    // Observers of
    // MONOTONIC metrics should never see the value decrease without a
    // reset (i.e., StartTimeUnixNano advances), otherwise a
    // decreasing MONOTONIC metric suggests an SDK bug.
    MONOTONIC = 0x20;

    // ASYNCHRONOUS may be set for any kind of metric, indicating it
    // was generated through asynchronous events in which the SDK
    // calls the application.  If ASYNCHRONOUS is not set, it implies
    // the event originated from the application calling the SDK.
    ASYNCHRONOUS = 0x40;
  }

  // Kind explains how the DataPoint was produced (called
  // "Structure"), how the point was aggregated with resepect to time
  // (called "Temporality"), whether it was computed asynchronously,
  // and (when the Structure is ADDING) whether the sum is not
  // monotonic.
  //
  // Kind names are generated from valid combinations of KindElement
  // by joining the effective KindElements using underscores.  There
  // are:
  //
  // - 3 possibilities for Temporality
  // - 3 possibilities for Structure/Monotonicity: Adding Monotonic,
  //     Adding Non-Monotonic, and Grouping
  // - 2 possibilities of being Asynchronous
  //
  // This makes 18 valid values.
  enum Kind {
    // INVALID_KIND is the default Kind, it MUST not be used.
    INVALID_KIND = 0;

    // The following codes are generated by a program.

    ADDING_MONOTONIC_INSTANTANEOUS              = 0x29; // ADDING|INSTANTANEOUS|MONOTONIC
    ADDING_MONOTONIC_INSTANTANEOUS_ASYNCHRONOUS = 0x69; // ADDING|INSTANTANEOUS|MONOTONIC|ASYNCHRONOUS
    ADDING_MONOTONIC_CUMULATIVE                 = 0x2c; // ADDING|CUMULATIVE|MONOTONIC
    ADDING_MONOTONIC_CUMULATIVE_ASYNCHRONOUS    = 0x6c; // ADDING|CUMULATIVE|MONOTONIC|ASYNCHRONOUS
    ADDING_MONOTONIC_DELTA                      = 0x2a; // ADDING|DELTA|MONOTONIC
    ADDING_MONOTONIC_DELTA_ASYNCHRONOUS         = 0x6a; // ADDING|DELTA|MONOTONIC|ASYNCHRONOUS

    ADDING_INSTANTANEOUS                        = 0x9 ; // ADDING|INSTANTANEOUS
    ADDING_INSTANTANEOUS_ASYNCHRONOUS           = 0x49; // ADDING|INSTANTANEOUS|ASYNCHRONOUS
    ADDING_CUMULATIVE                           = 0xc ; // ADDING|CUMULATIVE
    ADDING_CUMULATIVE_ASYNCHRONOUS              = 0x4c; // ADDING|CUMULATIVE|ASYNCHRONOUS
    ADDING_DELTA                                = 0xa ; // ADDING|DELTA
    ADDING_DELTA_ASYNCHRONOUS                   = 0x4a; // ADDING|DELTA|ASYNCHRONOUS

    GROUPING_INSTANTANEOUS                      = 0x11; // GROUPING|INSTANTANEOUS
    GROUPING_INSTANTANEOUS_ASYNCHRONOUS         = 0x51; // GROUPING|INSTANTANEOUS|ASYNCHRONOUS
    GROUPING_CUMULATIVE                         = 0x14; // GROUPING|CUMULATIVE
    GROUPING_CUMULATIVE_ASYNCHRONOUS            = 0x54; // GROUPING|CUMULATIVE|ASYNCHRONOUS
    GROUPING_DELTA                              = 0x12; // GROUPING|DELTA
    GROUPING_DELTA_ASYNCHRONOUS                 = 0x52; // GROUPING|DELTA|ASYNCHRONOUS
  }

  // Kind describes properties of the Metric that are necessary to
  // interpret the data and/or describe how it was produced.
  Kind kind = 5;
}

// Int64DataPoint is a single data point in a timeseries that describes the time-varying
// values of a SCALAR_INT64 metric.
message Int64DataPoint {
  // The set of labels that uniquely identify this timeseries.
  repeated opentelemetry.proto.common.v1.StringKeyValue labels = 1;

  // start_time_unix_nano is the time when the cumulative value was reset to zero.
  // This is used for Counter type only. For Gauge the value is not specified and
  // defaults to 0.
  //
  // The cumulative value is over the time interval (start_time_unix_nano, time_unix_nano].
  // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
  //
  // Value of 0 indicates that the timestamp is unspecified. In that case the timestamp
  // may be decided by the backend.
  fixed64 start_time_unix_nano = 2;

  // time_unix_nano is the moment when this value was recorded.
  // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
  fixed64 time_unix_nano = 3;

  // value itself.
  int64 value = 4;
}

// DoubleDataPoint is a single data point in a timeseries that describes the time-varying
// value of a SCALAR_DOUBLE metric.
message DoubleDataPoint {
  // The set of labels that uniquely identify this timeseries.
  repeated opentelemetry.proto.common.v1.StringKeyValue labels = 1;

  // start_time_unix_nano is the time when the cumulative value was reset to zero.
  // This is used for Counter type only. For Gauge the value is not specified and
  // defaults to 0.
  //
  // The cumulative value is over the time interval (start_time_unix_nano, time_unix_nano].
  // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
  //
  // Value of 0 indicates that the timestamp is unspecified. In that case the timestamp
  // may be decided by the backend.
  fixed64 start_time_unix_nano = 2;

  // time_unix_nano is the moment when this value was recorded.
  // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
  fixed64 time_unix_nano = 3;

  // value itself.
  double value = 4;
}

// HistogramDataPoint is a single data point in a timeseries that describes the time-varying
// values of a Histogram. A Histogram contains summary statistics for a population of values,
// it may optionally contain the distribution of those values across a set of buckets.
message HistogramDataPoint {
  // The set of labels that uniquely identify this timeseries.
  repeated opentelemetry.proto.common.v1.StringKeyValue labels = 1;

  // start_time_unix_nano is the time when the cumulative value was reset to zero.
  //
  // The cumulative value is over the time interval (start_time_unix_nano, time_unix_nano].
  // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
  //
  // Value of 0 indicates that the timestamp is unspecified. In that case the timestamp
  // may be decided by the backend.
  // Note: this field is always unspecified and ignored if MetricDescriptor.type==GAUGE_HISTOGRAM.
  fixed64 start_time_unix_nano = 2;

  // time_unix_nano is the moment when this value was recorded.
  // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
  fixed64 time_unix_nano = 3;

  // count is the number of values in the population. Must be non-negative. This value
  // must be equal to the sum of the "count" fields in buckets if a histogram is provided.
  uint64 count = 4;

  // sum of the values in the population. If count is zero then this field
  // must be zero. This value must be equal to the sum of the "sum" fields in buckets if
  // a histogram is provided.
  double sum = 5;

  // Bucket contains values for a bucket.
  message Bucket {
    // The number of values in each bucket of the histogram, as described by
    // bucket_options.
    uint64 count = 1;

    // Exemplars are example points that may be used to annotate aggregated
    // Histogram values. They are metadata that gives information about a
    // particular value added to a Histogram bucket.
    message Exemplar {
      // Value of the exemplar point. It determines which bucket the exemplar belongs to.
      // If bucket_options define bounds for this bucket then this value must be within
      // the defined bounds.
      double value = 1;

      // time_unix_nano is the moment when this exemplar was recorded.
      // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
      fixed64 time_unix_nano = 2;

      // exemplar_attachments are contextual information about the example value.
      // Keys in this list must be unique.
      repeated opentelemetry.proto.common.v1.StringKeyValue attachments = 3;
    }

    // exemplar is an optional representative value of the bucket.
    Exemplar exemplar = 2;
  }

  // buckets is an optional field contains the values of histogram for each bucket.
  //
  // The sum of the values in the buckets "count" field must equal the value in the count field.
  //
  // The number of elements in buckets array must be by one greater than the
  // number of elements in bucket_bounds array.
  //
  // Note: if HistogramDataPoint.bucket_options defines bucket bounds then this field
  // must also be present and number of elements in this field must be equal to the
  // number of buckets defined by bucket_options.
  repeated Bucket buckets = 6;

  // A histogram may optionally contain the distribution of the values in the population.
  // In that case one of the option fields below and "buckets" field both must be defined.
  // Otherwise all option fields and "buckets" field must be omitted in which case the
  // distribution of values in the histogram is unknown and only the total count and sum are known.

  // explicit_bounds is the only supported bucket option currently.
  // TODO: Add more bucket options.

  // explicit_bounds specifies buckets with explicitly defined bounds for values.
  // The bucket boundaries are described by "bounds" field.
  //
  // This defines size(bounds) + 1 (= N) buckets. The boundaries for bucket
  // at index i are:
  //
  // [0, bounds[i]) for i == 0
  // [bounds[i-1], bounds[i]) for 0 < i < N-1
  // [bounds[i], +infinity) for i == N-1
  // The values in bounds array must be strictly increasing and > 0.
  //
  // Note: only [a, b) intervals are currently supported for each bucket. If we decides
  // to also support (a, b] intervals we should add support for these by defining a boolean
  // value which decides what type of intervals to use.
  repeated double explicit_bounds = 7;
}

// SummaryDataPoint is a single data point in a timeseries that describes the time-varying
// values of a Summary metric.
message SummaryDataPoint {
  // The set of labels that uniquely identify this timeseries.
  repeated opentelemetry.proto.common.v1.StringKeyValue labels = 1;

  // start_time_unix_nano is the time when the cumulative value was reset to zero.
  //
  // The cumulative value is over the time interval (start_time_unix_nano, time_unix_nano].
  // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
  //
  // Value of 0 indicates that the timestamp is unspecified. In that case the timestamp
  // may be decided by the backend.
  fixed64 start_time_unix_nano = 2;

  // time_unix_nano is the moment when this value was recorded.
  // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
  fixed64 time_unix_nano = 3;

  // The total number of recorded values since start_time. Optional since
  // some systems don't expose this.
  uint64 count = 4;

  // The total sum of recorded values since start_time. Optional since some
  // systems don't expose this. If count is zero then this field must be zero.
  double sum = 5;

  // Represents the value at a given percentile of a distribution.
  //
  // To record Min and Max values following conventions are used:
  // - The 100th percentile is equivalent to the maximum value observed.
  // - The 0th percentile is equivalent to the minimum value observed.
  //
  // See the following issue for more context:
  // https://github.com/open-telemetry/opentelemetry-proto/issues/125
  message ValueAtPercentile {
    // The percentile of a distribution. Must be in the interval
    // [0.0, 100.0].
    double percentile = 1;

    // The value at the given percentile of a distribution.
    double value = 2;
  }

  // A list of values at different percentiles of the distribution calculated
  // from the current snapshot. The percentiles must be strictly increasing.
  repeated ValueAtPercentile percentile_values = 6;
}
