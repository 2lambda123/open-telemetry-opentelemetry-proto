// Copyright 2019, OpenTelemetry Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package opentelemetry.proto.metrics.v1;

import "opentelemetry/proto/common/v1/common.proto";
import "opentelemetry/proto/resource/v1/resource.proto";

option java_multiple_files = true;
option java_package = "io.opentelemetry.proto.metrics.v1";
option java_outer_classname = "MetricsProto";
option go_package = "github.com/open-telemetry/opentelemetry-proto/gen/go/metrics/v1";

// A collection of InstrumentationLibraryMetrics from a Resource.
message ResourceMetrics {
  // The resource for the metrics in this message.
  // If this field is not set then no resource info is known.
  opentelemetry.proto.resource.v1.Resource resource = 1;

  // A list of metrics that originate from a resource.
  repeated InstrumentationLibraryMetrics instrumentation_library_metrics = 2;
}

// A collection of Metrics produced by an InstrumentationLibrary.
message InstrumentationLibraryMetrics {
  // The instrumentation library information for the metrics in this message.
  // If this field is not set then no library info is known.
  opentelemetry.proto.common.v1.InstrumentationLibrary instrumentation_library = 1;

  // A list of metrics that originate from an instrumentation library.
  repeated Metric metrics = 2;
}

// Defines a Metric which has one or more timeseries.
//
// The data model and relation between entities is shown in the
// diagram below. Here, "DataPoint" is the term used to refer to any
// one of the specific data point value types, and "points" is the term used
// to refer to any one of the lists of points contained in the Metric.
//
// - Metric is composed of a MetricDescriptor and a list of data points.
// - MetricDescriptor contains a name, description, unit, type, and temporarility.
// - Points is a list of DataPoints (shown vertically).
// - DataPoint contains timestamps, labels, and one of the possible value type fields.
//
//     Metric
//  +----------+         +------------------------+
//  |descriptor|-------->| MetricDescriptor       |
//  |          |         | name                   |
//  |          |         | description            |
//  |          |         | unit                   |
//  |    points|--+      | type                   |
//  +----------+  |      | temporarility          |
//                |      +------------------------+
//                |
//                |      +---------------------------+
//                |      |DataPoint 1                |
//                v      |+------+------+   +------+ |
//             +-----+   ||label |label |...|label | |
//             |  1  |-->||value1|value2|...|valueN| |
//             +-----+   |+------+------+   +------+ |
//             |  .  |   |+-----+                    |
//             |  .  |   ||value|                    |
//             |  .  |   |+-----+                    |
//             |  .  |   +---------------------------+
//             |  .  |                   .
//             |  .  |                   .
//             |  .  |                   .
//             |  .  |   +---------------------------+
//             |  .  |   |DataPoint M                |
//             +-----+   |+------+------+   +------+ |
//             |  M  |-->||label |label |...|label | |
//             +-----+   ||value1|value2|...|valueN| |
//                       |+------+------+   +------+ |
//                       |+-----+                    |
//                       ||value|                    |
//                       |+-----+                    |
//                       +---------------------------+
//
// All DataPoint types have three common fields:
// - Labels zero or more key-value pairs associated with the data point.
// - StartTimeUnixNano MUST be to the start of the interval, when an aggregation
//   was applied, but may be omitted for raw data points.
// - TimeUnixNano MUST be set to:
//   - the end of the interval, if aggregation was applied
//   - the instant of the event, if no aggregation was applied.
message Metric {
  // metric_descriptor describes the Metric.
  //
  // N.B. "Descriptor" is a reserved term in protobuf, protoc
  // generates a field named "Descriptor_" thus we use
  // "metric_descriptor".
  MetricDescriptor metric_descriptor = 1;

  // Data is a list of one or more DataPoints for a single metric. Only one of the
  // following fields is used for the data, depending on the type of the metric defined
  // by MetricDescriptor.type field.
  repeated Int64DataPoint int64_data_points = 2;
  repeated DoubleDataPoint double_data_points = 3;
  repeated HistogramDataPoint histogram_data_points = 4;
  repeated SummaryDataPoint summary_data_points = 5;
}

// Defines a metric type and its schema.
message MetricDescriptor {
  // name of the metric, including its DNS name prefix. It must be unique.
  string name = 1;

  // description of the metric, which can be used in documentation.
  string description = 2;

  // unit in which the metric value is reported. Follows the format
  // described by http://unitsofmeasure.org/ucum.html.
  string unit = 3;

  // Type is the type of value(s) a metric represents.  Type
  // determines which field of the DataPoint will be used for Metrics
  // with this descriptor.  See the definition of Kind for detail on
  // which aggregations may be expressed for which instruments using
  // which value types.
  //
  // Types are distinguished by whether a data point of its type
  // can _possibly_ represent more than one individual input
  // measurement.  Single-value data points have a definite one-to-one
  // relationship with input measurements.  Multi-value data points,
  // by contrast, represent one or more input measurements.
  //
  // Types are also distinguished by whether the value supports
  // subtraction.  Not all value types support subtraction, but types
  // which do can be converted from CUMULATIVE kind into DELTA kind.
  enum Type {
    // INVALID_TYPE is the default Type, it MUST not be used.
    INVALID_VALUE_TYPE = 0;

    // ScalarInt64 implies that the value is found in
    // Metric.int64_data_points[].value.  This indicates a
    // single-value data point.  Supports subtraction when the Kind is
    // ADDING or ADDING_MONOTONIC.
    SCALAR_INT64 = 1;

    // ScalarDouble implies that the value is found in
    // Metric.double_data_points[].value.  This indicates a
    // single-value data point.  Supports subtraction when the Kind is
    // ADDING or ADDING_MONOTONIC.
    SCALAR_DOUBLE = 2;

    // Histogram implies that the value is found in
    // Metric.histogram_data_points[].histogram.  This indicates a
    // multi-value data point.  Supports subtraction for Kinds.
    HISTOGRAM = 3;

    // Summary implies that the value is found in
    // Metric.summary_data_points[].summary.  This indicates a
    // multi-value data point.  Does not support subtraction.
    SUMMARY = 4;

    // TODO(#159): add RAW_INT64 and RAW_DOUBLE value types.  These
    // indicate single-value data points.
  }

  // Type is the type of values this metric has.
  Type value_type = 4;

  // Temporality is the temporal quality values of a metric have. It
  // describes how those values relate to the time interval over which they
  // are reported.
  enum Temporality {
    // INVALID_TEMPORALITY is the default Temporality, it MUST not be
    // used.
    INVALID_TEMPORALITY = 0;

    // DELTA is a metric whose values are the aggregation of measurements
    // made over a time interval. Successive metrics contain aggregation of
    // values from continuous and non-overlapping intervals.
    //
    // The values for a DELTA metric are based only on the time interval
    // associated with one measurement cycle. There is no dependency on
    // previous measurements like is the case for CUMULATIVE metrics.
    //
    // For example, consider a system measuring the number of requests that
    // it receives and reports the sum of these requests every second as a
    // DELTA metric:
    //
    //   1. The system starts receiving at time=t_0.
    //   2. A request is received, the system measures 1 request.
    //   3. A request is received, the system measures 1 request.
    //   4. A request is received, the system measures 1 request.
    //   5. The 1 second collection cycle ends. A metric is exported for the
    //      number of requests received over the interval of time t_0 to
    //      t_0+1 with a value of 3.
    //   6. A request is received, the system measures 1 request.
    //   7. A request is received, the system measures 1 request.
    //   8. The 1 second collection cycle ends. A metric is exported for the
    //      number of requests received over the interval of time t_0+1 to
    //      t_0+2 with a value of 2.
    DELTA = 1;

    // CUMULATIVE is a metric whose values are the aggregation of
    // successively made measurements from a fixed start time until the last
    // reported measurement. This means that current values of a CUMULATIVE
    // metric depend on all previous measurements since the start time.
    // Because of this, the sender is required to retain this state in some
    // form. If this state is lost or invalidated, the CUMULATIVE metric
    // values MUST be reset and a new fixed start time following the last
    // reported measurement time sent MUST be used.
    //
    // For example, consider a system measuring the number of requests that
    // it receives and reports the sum of these requests every second as a
    // CUMULATIVE metric:
    //
    //   1. The system starts receiving at time=t_0.
    //   2. A request is received, the system measures 1 request.
    //   3. A request is received, the system measures 1 request.
    //   4. A request is received, the system measures 1 request.
    //   5. The 1 second collection cycle ends. A metric is exported for the
    //      number of requests received over the interval of time t_0 to
    //      t_0+1 with a value of 3.
    //   6. A request is received, the system measures 1 request.
    //   7. A request is received, the system measures 1 request.
    //   8. The 1 second collection cycle ends. A metric is exported for the
    //      number of requests received over the interval of time t_0 to
    //      t_0+2 with a value of 5.
    //   9. The system experiences a fault and loses state.
    //   10. The system recovers and resumes receiving at time=t_1.
    //   11. A request is received, the system measures 1 request.
    //   12. The 1 second collection cycle ends. A metric is exported for the
    //      number of requests received over the interval of time t_1 to
    //      t_0+1 with a value of 1.
    //
    // Note that the first value in a sequence of CUMULATIVE metrics
    // after a reset is equivalent in value to a DELTA metric for the
    // period since the reset.  Although a CUMULATIVE metric could
    // technically be reset after every collection event and still be
    // described as CUMULATIVE, exporters should use DELTA if there is
    // no intention of repeating the StartTimeUnixNano timestamp.
    CUMULATIVE = 2;
  }

  // Structure is the structural quality of a metric, indicating
  // whether the input measurements represent part of an individual
  // sum or are considered individual measurements.
  enum Structure {
    // INVALID_STRUCTURE is the default Structure, it MUST not be
    // used.
    INVALID_STRUCTURE = 0;

    // GROUPING structure means the value has been computed from
    // individual input values considered part of a distribution.
    // GROUPING structure implies the sum of measurements is not
    // necessarily meaningful.
    //
    // Value of this kind are defined as a current measurement of the
    // metric when represented by single-value data points.
    GROUPING = 1;

    // ADDING_MONOTONIC structure means the measurement determines a
    // sum.  For DELTA kind this is expressed as the change in sum
    // since the last collection.  For CUMULATIVE kind this is
    // expressed as the last collected value of the sum since
    // reporting began.
    //
    // ADDING_MONOTONIC indicates that the calculated sum is
    // non-decreasing, therefore can be monitored as a non-negative
    // rate of change.
    ADDING_MONOTONIC = 2;

    // ADDING structure means the measurement determines a sum.  For
    // DELTA kind this is expressed as the change in sum since the
    // last collection.  For CUMULATIVE kind this is expressed as the
    // last collected value of the sum since reporting began.
    ADDING = 3;
  }

  // Continuity describes how the measurement was captured,
  // indicating whether measurements represent application-level
  // events or were generated through a callback invoked by the SDK.
  enum Continuity {
    // INVALID_CONTINUITY is the default Continuity, it MUST not be
    // used.
    INVALID_CONTINUITY = 0;

    // CONTINUOUS implies the event originated from the application
    // calling the SDK with a measurement and possibly a tracing
    // context.
    CONTINUOUS = 1;

    // SNAPSHOT may be set for any kind of metric, indicating it
    // was generated through a callback invoked deliberately by the
    // SDK.  In SNAPSHOT measurements, TimeUnixNano values depend
    // on the SDK's decision to collect, not the application.
    //
    // SNAPSHOT measurements may be used to define point-in-time
    // ratios, as data points from the same callback execution MUST
    // share a single logical timestamp.
    SNAPSHOT = 2;
  }

  // Temporality is DELTA or CUMULATIVE.  A value MUST be set.
  Temporality temporality = 5;

  // Structure is ADDING_MONOTONIC, ADDING, or GROUPING.  A value MUST be set.
  Structure structure = 6;

  // Continuity is CONTINUOUS or SNAPSHOT.  A value MUST be set.
  Continuity continuity = 7;
  
  // All 12 combinations of Temporality, Structure, and Coninuity
  // describe a meaningful expression of metric data.  Users familiar
  // with the user-facing OpenTelemetry Metrics API will recognize
  // these 12 values as comprised of 6 kinds of instrument combined
  // with 2 values for temporality.  Structure and Continuity form the
  // semantic basis of the various metric instruments, corresponding
  // with the API Specification, while Temporality is an orthogonal
  // concept.  The instrument mapping:
  //
  //   Instrument         Structure        Continuity
  //   ----------------------------------------------
  //   Counter            ADDING_MONOTONIC CONTINUOUS
  //   UpDownCounter      ADDING           CONTINUOUS
  //   ValueRecorder      GROUPING         CONTINUOUS
  //   SumObserver        ADDING_MONOTONIC SNAPSHOT
  //   UpDownSumObserver  ADDING           SNAPSHOT
  //   ValueObserver      GROUPING         SNAPSHOT
  //
  // Several observations help simplify our understanding of
  // Temporality and Structure.
  //
  // About Temporality:
  //
  //   DELTA and CUMULATIVE temporalities are practically identical in
  //   interpretation, though they differ in intention.  In both
  //   cases, the data point represents part or all of the data
  //   collected across an interval of time.  The CUMULATIVE kind
  //   indicates that the client does not "reset" and that
  //   StartTimeUnixNano will be held as a constant across data points
  //   for a single process.
  //
  // About Structure:
  //
  //   ADDING_MONOTONIC and ADDING structures are practically
  //   identical in form, but commonly differ in interpretation.  In
  //   both cases, individual data points are meant to be combined
  //   into a sum.  In both cases, knowing the Metric is a sum
  //   indicates the variable may be monitored as a rate of change.
  //   In the monotonic case, the sum has a useful non-negative rate.
  //
  //   GROUPING structure data points represent individual
  //   measurements, meant to be combined into a distribution.  The
  //   sum of these data may be meaningful, but individual
  //   measurements are the focus of these metrics.
  //
  // About Continuity:
  //
  //   CONTINUOUS kind data points result directly from
  //   application-level events, therefore the count of events defines
  //   a meaningful rate to the user.  Identical CONTINUOUS data
  //   points (with the same Resource and TimeUnixNano) are considered
  //   conincidental.
  //
  //   SNAPSHOT kind data points result from callbacks invoked by the
  //   SDK, therefore are called in SDK context (i.e., not traced) and
  //   the rate of measurements does not define a meaningful rate to
  //   the user.  Identical SNAPSHOT data points (with the same
  //   Resource and TimeUnixNano) are considered invalid, as only one
  //   Snapshot can be taken per instant per SDK.  Measurements of a
  //   SNAPSHOT metric are recorded for all label sets at the same
  //   logical time, therefore can be used to calculate meaningful
  //   point-in-time ratios.
}

// Int64DataPoint is a single data point in a timeseries that describes the time-varying
// values of a int64 metric.
message Int64DataPoint {
  // The set of labels that uniquely identify this timeseries.
  repeated opentelemetry.proto.common.v1.StringKeyValue labels = 1;

  // StartTimeUnixNano is the moment when aggregation began over a
  // period of time to compute the data point.  When this value is
  // omitted it implies no aggregation was applied, in which case the
  // start time may also be considered equal to TimeUnixNano.
  //
  // The value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on
  // 1 January 1970.
  fixed64 start_time_unix_nano = 2;

  // time_unix_nano is the moment when this value was recorded.
  //
  // The value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on
  // 1 January 1970.
  fixed64 time_unix_nano = 3;

  // value itself.
  int64 value = 4;
}

// DoubleDataPoint is a single data point in a timeseries that describes the time-varying
// value of a double metric.
message DoubleDataPoint {
  // The set of labels that uniquely identify this timeseries.
  repeated opentelemetry.proto.common.v1.StringKeyValue labels = 1;

  // StartTimeUnixNano is the moment when aggregation began over a
  // period of time to compute the data point.  When this value is
  // omitted it implies no aggregation was applied, in which case the
  // start time may also be considered equal to TimeUnixNano.
  //
  // The value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on
  // 1 January 1970.
  fixed64 start_time_unix_nano = 2;

  // time_unix_nano is the moment when this value was recorded.
  //
  // The value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on
  // 1 January 1970.
  fixed64 time_unix_nano = 3;

  // value itself.
  double value = 4;
}

// HistogramDataPoint is a single data point in a timeseries that describes the time-varying
// values of a Histogram. A Histogram contains summary statistics for a population of values,
// it may optionally contain the distribution of those values across a set of buckets.
message HistogramDataPoint {
  // The set of labels that uniquely identify this timeseries.
  repeated opentelemetry.proto.common.v1.StringKeyValue labels = 1;

  // StartTimeUnixNano is the moment when aggregation began over a
  // period of time to compute the data point.  When this value is
  // omitted it implies no aggregation was applied, in which case the
  // start time may also be considered equal to TimeUnixNano.
  //
  // The value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on
  // 1 January 1970.
  fixed64 start_time_unix_nano = 2;

  // time_unix_nano is the moment when this value was recorded.
  //
  // The value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on
  // 1 January 1970.
  fixed64 time_unix_nano = 3;

  // count is the number of values in the population. Must be non-negative. This value
  // must be equal to the sum of the "count" fields in buckets if a histogram is provided.
  uint64 count = 4;

  // sum of the values in the population. If count is zero then this field
  // must be zero. This value must be equal to the sum of the "sum" fields in buckets if
  // a histogram is provided.
  double sum = 5;

  // Bucket contains values for a bucket.
  message Bucket {
    // The number of values in each bucket of the histogram, as described by
    // bucket_options.
    uint64 count = 1;

    // Exemplars are example points that may be used to annotate aggregated
    // Histogram values. They are metadata that gives information about a
    // particular value added to a Histogram bucket.
    message Exemplar {
      // Value of the exemplar point. It determines which bucket the exemplar belongs to.
      // If bucket_options define bounds for this bucket then this value must be within
      // the defined bounds.
      double value = 1;

      // time_unix_nano is the moment when this exemplar was recorded.
      // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
      fixed64 time_unix_nano = 2;

      // exemplar_attachments are contextual information about the example value.
      // Keys in this list must be unique.
      repeated opentelemetry.proto.common.v1.StringKeyValue attachments = 3;
    }

    // exemplar is an optional representative value of the bucket.
    Exemplar exemplar = 2;
  }

  // buckets is an optional field contains the values of histogram for each bucket.
  //
  // The sum of the values in the buckets "count" field must equal the value in the count field.
  //
  // The number of elements in buckets array must be by one greater than the
  // number of elements in bucket_bounds array.
  //
  // Note: if HistogramDataPoint.bucket_options defines bucket bounds then this field
  // must also be present and number of elements in this field must be equal to the
  // number of buckets defined by bucket_options.
  repeated Bucket buckets = 6;

  // A histogram may optionally contain the distribution of the values in the population.
  // In that case one of the option fields below and "buckets" field both must be defined.
  // Otherwise all option fields and "buckets" field must be omitted in which case the
  // distribution of values in the histogram is unknown and only the total count and sum are known.

  // explicit_bounds is the only supported bucket option currently.
  // TODO: Add more bucket options.

  // explicit_bounds specifies buckets with explicitly defined bounds for values.
  // The bucket boundaries are described by "bounds" field.
  //
  // This defines size(bounds) + 1 (= N) buckets. The boundaries for bucket
  // at index i are:
  //
  // (-infinity, bounds[i]) for i == 0
  // [bounds[i-1], bounds[i]) for 0 < i < N-1
  // [bounds[i], +infinity) for i == N-1
  // The values in bounds array must be strictly increasing.
  //
  // Note: only [a, b) intervals are currently supported for each bucket except the first one.
  // If we decide to also support (a, b] intervals we should add support for these by defining
  // a boolean value which decides what type of intervals to use.
  repeated double explicit_bounds = 7;
}

// SummaryDataPoint is a single data point in a timeseries that describes the time-varying
// values of a Summary metric.
message SummaryDataPoint {
  // The set of labels that uniquely identify this timeseries.
  repeated opentelemetry.proto.common.v1.StringKeyValue labels = 1;

  // StartTimeUnixNano is the moment when aggregation began over a
  // period of time to compute the data point.  When this value is
  // omitted it implies no aggregation was applied, in which case the
  // start time may also be considered equal to TimeUnixNano.
  //
  // The value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on
  // 1 January 1970.
  fixed64 start_time_unix_nano = 2;

  // time_unix_nano is the moment when this value was recorded.
  //
  // The value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on
  // 1 January 1970.
  fixed64 time_unix_nano = 3;

  // The total number of recorded values since start_time. Optional since
  // some systems don't expose this.
  uint64 count = 4;

  // The total sum of recorded values since start_time. Optional since some
  // systems don't expose this. If count is zero then this field must be zero.
  double sum = 5;

  // Represents the value at a given quantile of a distribution.
  //
  // To record Min and Max values following conventions are used:
  // - The 1.0 quantile is equivalent to the maximum value observed.
  // - The 0.0 quantile is equivalent to the minimum value observed.
  //
  // See the following issue for more context:
  // https://github.com/open-telemetry/opentelemetry-proto/issues/125
  message ValueAtQuantile {
    // The quantile of a distribution. Must be in the interval
    // [0.0, 1.0].
    double quantile = 1;

    // The value at the given quantile of a distribution.
    double value = 2;
  }

  // A list of values at different quantiles of the distribution calculated
  // from the current snapshot. The quantiles must be strictly increasing.
  repeated ValueAtQuantile quantile_values = 6;
}
